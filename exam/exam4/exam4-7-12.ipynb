{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85ab72e",
   "metadata": {},
   "source": [
    "### 4-7-12. 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08d23caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d67cbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2951772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237649be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc68bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2, 3)] # petal length, width\n",
    "y = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516fd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f9fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((len(X), 1)), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f9eb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.4, 0.2]), array([1. , 1.4, 0.2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], X_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7341436",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X_b)\n",
    "rnd_indices = np.random.permutation(N)\n",
    "\n",
    "train_size = int(N * 0.7)\n",
    "valid_size = int(N * 0.2)\n",
    "test_size = int(N * 0.1)\n",
    "\n",
    "X_train = X_b[rnd_indices[:train_size]]\n",
    "y_train = y[rnd_indices[:train_size]]\n",
    "\n",
    "X_valid = X_b[rnd_indices[train_size: train_size+valid_size]]\n",
    "y_valid = y[rnd_indices[train_size: train_size+valid_size]]\n",
    "\n",
    "X_test = X_b[rnd_indices[-test_size:]]\n",
    "y_test = y[rnd_indices[-test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "648a8622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 3), (30, 3), (15, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "428135d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    m = len(Y)\n",
    "    n_classes = len(iris.target_names)\n",
    "    y_one_hot = np.zeros((m, n_classes))\n",
    "    y_one_hot[np.arange(m), Y] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "adabccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = one_hot(y_train)\n",
    "y_valid_one_hot = one_hot(y_valid)\n",
    "y_test_one_hot = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1253a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 3), (30, 3), (15, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape, y_valid_one_hot.shape, y_test_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0c9c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_function(logits):\n",
    "    exps = np.exp(logits)\n",
    "    total_exps = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / total_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f012cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_theta(n_iterations, eta, m, train_data, valid_data):\n",
    "    t_X, t_y = train_data\n",
    "    v_X, v_y = valid_data\n",
    "    theta = np.random.randn(t_X.shape[-1], len(iris.target_names))\n",
    "\n",
    "    best_iteration = n_iterations\n",
    "    best_loss = float(\"inf\")\n",
    "    best_theta = None\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        logits = t_X.dot(theta)\n",
    "        prob = softmax_function(logits)\n",
    "        loss = -np.mean(np.sum(t_y * np.log(prob), axis=1))\n",
    "        gradients = 1/m * t_X.T.dot(prob - t_y)\n",
    "        theta = theta - eta * gradients\n",
    "        \n",
    "        valid_logits = v_X.dot(theta)\n",
    "        valid_prob = softmax_function(valid_logits)\n",
    "        valid_loss = -np.mean(np.sum(v_y * np.log(valid_prob), axis=1))\n",
    "        if iteration % (n_iterations/10) == 0:\n",
    "            print(f\"iter: {iteration}, loss: {loss}, valid: {valid_loss}\")\n",
    "\n",
    "        if (iteration+1) % (n_iterations/2) == 0:\n",
    "            eta /= 10\n",
    "            print(f\"eta: {eta}\")\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_iteration = iteration\n",
    "            best_theta = theta.copy()\n",
    "        else:\n",
    "            print(\"Early Stopped\")\n",
    "            break\n",
    "    \n",
    "    return best_iteration, best_loss, best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f0dfe684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 5.15463399503697, valid: 4.239973802925364\n",
      "iter: 1000, loss: 0.3005748539065718, valid: 0.29048238914537744\n",
      "iter: 2000, loss: 0.2328114598805926, valid: 0.22390518678274468\n",
      "iter: 3000, loss: 0.19705570609315443, valid: 0.19333560741124828\n",
      "iter: 4000, loss: 0.17432282046961367, valid: 0.17561167704176447\n",
      "eta: 0.01\n",
      "iter: 5000, loss: 0.15846638367394053, valid: 0.16397787316126244\n",
      "iter: 6000, loss: 0.1571380061384765, valid: 0.16302628661268248\n",
      "iter: 7000, loss: 0.15584801842421148, valid: 0.16210548694723306\n",
      "iter: 8000, loss: 0.15459473461027975, valid: 0.16121392298652848\n",
      "iter: 9000, loss: 0.15337656736110875, valid: 0.16035014580877813\n",
      "eta: 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9999, 0.1595136251587691)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0, t1 = 5, 50\n",
    "\n",
    "eta = 0.1\n",
    "m = len(X_train)\n",
    "n_iterations = 10000\n",
    "\n",
    "best_iteration, best_loss, best_theta = fit_theta(\n",
    "    n_iterations, eta, m, (X_train, y_train_one_hot), (X_valid, y_valid_one_hot)\n",
    ")\n",
    "best_iteration, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9bb0ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(x_data, y_data, Theta):\n",
    "    y_pred = np.argmax(softmax_function(x_data.dot(Theta)), axis=1)\n",
    "    acc = np.mean(y_pred == y_data)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8098757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9523809523809523\n",
      "valid acc: 1.0\n",
      "test acc: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"train acc: {calc_acc(X_train, y_train, best_theta)}\")\n",
    "print(f\"valid acc: {calc_acc(X_valid, y_valid, best_theta)}\")\n",
    "print(f\"test acc: {calc_acc(X_test, y_test, best_theta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df42601",
   "metadata": {},
   "source": [
    "### merge train & valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "afb0b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = X_b[rnd_indices[:train_size+valid_size]]\n",
    "y_train_valid = y[rnd_indices[:train_size+valid_size]]\n",
    "y_train_valid_one_hot = one_hot(y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "69cd9fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 4.042312468813351, valid: 4.008925191232171\n",
      "iter: 1000, loss: 0.2790599386013156, valid: 0.2983153929374564\n",
      "iter: 2000, loss: 0.21168015135082627, valid: 0.22043429622446103\n",
      "iter: 3000, loss: 0.1793880245943859, valid: 0.18342536611058546\n",
      "iter: 4000, loss: 0.1595715338208858, valid: 0.1621639745813902\n",
      "eta: 0.01\n",
      "iter: 5000, loss: 0.1459931078178252, valid: 0.14842409810673646\n",
      "iter: 6000, loss: 0.14486317535755613, valid: 0.14730990717032927\n",
      "iter: 7000, loss: 0.1437669201639916, valid: 0.14623328713838724\n",
      "iter: 8000, loss: 0.14270280083212702, valid: 0.14519230359593477\n",
      "iter: 9000, loss: 0.14166937043819136, valid: 0.14418515170271107\n",
      "eta: 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9999, 0.143211105194879)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0, t1 = 5, 50\n",
    "\n",
    "eta = 0.1\n",
    "m = len(X_train)\n",
    "n_iterations = 10000\n",
    "\n",
    "best_iteration, best_loss, best_theta = fit_theta(\n",
    "    n_iterations, eta, m, (X_train_valid, y_train_valid_one_hot), (X_test, y_test_one_hot)\n",
    ")\n",
    "best_iteration, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "583dfa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train&valid acc: 0.9629629629629629\n",
      "test acc: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"train&valid acc: {calc_acc(X_train_valid, y_train_valid, best_theta)}\")\n",
    "print(f\"test acc: {calc_acc(X_test, y_test, best_theta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea90fd",
   "metadata": {},
   "source": [
    "### add l2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "15f193ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_theta_l2(n_iterations, eta, m, train_data, valid_data, alpha=0.1):\n",
    "    t_X, t_y = train_data\n",
    "    v_X, v_y = valid_data\n",
    "    theta = np.random.randn(t_X.shape[-1], len(iris.target_names))\n",
    "\n",
    "    best_iteration = n_iterations\n",
    "    best_loss = float(\"inf\")\n",
    "    best_theta = None\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        logits = t_X.dot(theta)\n",
    "        prob = softmax_function(logits)\n",
    "        \n",
    "        cross_entropy = -np.mean(np.sum(t_y * np.log(prob), axis=1))\n",
    "        l2_loss = 1/2 * np.sum(np.square(theta[1:]))\n",
    "        loss = cross_entropy + alpha * l2_loss\n",
    "        \n",
    "        gradients = 1/m * t_X.T.dot(prob - t_y) + np.r_[np.zeros([1, len(iris.target_names)]), alpha * theta[1:]]\n",
    "        theta = theta - eta * gradients\n",
    "        \n",
    "        # valid\n",
    "        valid_logits = v_X.dot(theta)\n",
    "        valid_prob = softmax_function(valid_logits)\n",
    "        \n",
    "        valid_cross_entropy = -np.mean(np.sum(v_y * np.log(valid_prob), axis=1))\n",
    "        valid_l2_loss = 1/2 * np.sum(np.square(theta[1:]))\n",
    "        valid_loss = valid_cross_entropy + alpha * valid_l2_loss\n",
    "        if iteration % (n_iterations/10) == 0:\n",
    "            print(f\"iter: {iteration}, loss: {loss}, valid: {valid_loss}\")\n",
    "\n",
    "        if (iteration+1) % (n_iterations/2) == 0:\n",
    "            eta /= 10\n",
    "            print(f\"eta: {eta}\")\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_iteration = iteration\n",
    "            best_theta = theta.copy()\n",
    "        else:\n",
    "            print(\"Early Stopped\")\n",
    "            break\n",
    "    \n",
    "    return best_iteration, best_loss, best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4a52ce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 2.5739340308515044, valid: 1.4555216727724654\n",
      "iter: 1000, loss: 0.30960747187940374, valid: 0.2901711292548832\n",
      "iter: 2000, loss: 0.23799746620167672, valid: 0.22404962271163822\n",
      "iter: 3000, loss: 0.200418246337554, valid: 0.19351294735973182\n",
      "iter: 4000, loss: 0.17669677556810404, valid: 0.17575601104802205\n",
      "eta: 0.01\n",
      "iter: 5000, loss: 0.16024940538769064, valid: 0.16408327349150362\n",
      "iter: 6000, loss: 0.1588754264400782, valid: 0.16312795708289976\n",
      "iter: 7000, loss: 0.15754174045914016, valid: 0.16220347611235678\n",
      "iter: 8000, loss: 0.1562465548901227, valid: 0.16130828163827415\n",
      "iter: 9000, loss: 0.15498818306575357, valid: 0.16044092657669562\n",
      "eta: 0.001\n",
      "best iter: 9999, loss: 0.15960088566552796\n"
     ]
    }
   ],
   "source": [
    "t0, t1 = 5, 50\n",
    "\n",
    "eta = 0.1\n",
    "m = len(X_train)\n",
    "n_iterations = 10000\n",
    "\n",
    "best_iteration, best_loss, best_theta = fit_theta(\n",
    "    n_iterations, eta, m, (X_train, y_train_one_hot), (X_valid, y_valid_one_hot)\n",
    ")\n",
    "print(f\"best iter: {best_iteration}, loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e9ded37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.9523809523809523\n",
      "valid acc: 1.0\n",
      "test acc: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"train acc: {calc_acc(X_train, y_train, best_theta)}\")\n",
    "print(f\"valid acc: {calc_acc(X_valid, y_valid, best_theta)}\")\n",
    "print(f\"test acc: {calc_acc(X_test, y_test, best_theta)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82c8d6",
   "metadata": {},
   "source": [
    "### merge train & valid on l2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "357e3a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 1.539837257281275, valid: 1.301851057985813\n",
      "iter: 1000, loss: 0.2825968364635875, valid: 0.31047397209595096\n",
      "iter: 2000, loss: 0.21462893504639358, valid: 0.224897167645095\n",
      "iter: 3000, loss: 0.18119560465857634, valid: 0.1852442579417542\n",
      "iter: 4000, loss: 0.16071799025523578, valid: 0.16294233213017836\n",
      "eta: 0.01\n",
      "iter: 5000, loss: 0.14675765310908595, valid: 0.14872524732362266\n",
      "iter: 6000, loss: 0.1455991638666448, valid: 0.1475789683945682\n",
      "iter: 7000, loss: 0.1444757018601901, valid: 0.14647226935772312\n",
      "iter: 8000, loss: 0.14338564679217902, valid: 0.14540306559662106\n",
      "iter: 9000, loss: 0.1423274781480785, valid: 0.1443694153769135\n",
      "eta: 0.001\n",
      "best iter: 9999, loss: 0.1433704916480228\n"
     ]
    }
   ],
   "source": [
    "t0, t1 = 5, 50\n",
    "\n",
    "eta = 0.1\n",
    "m = len(X_train)\n",
    "n_iterations = 10000\n",
    "\n",
    "best_iteration, best_loss, best_theta = fit_theta(\n",
    "    n_iterations, eta, m, (X_train_valid, y_train_valid_one_hot), (X_test, y_test_one_hot)\n",
    ")\n",
    "print(f\"best iter: {best_iteration}, loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cd37e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train&valid acc: 0.9629629629629629\n",
      "test acc: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"train&valid acc: {calc_acc(X_train_valid, y_train_valid, best_theta)}\")\n",
    "print(f\"test acc: {calc_acc(X_test, y_test, best_theta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0648a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
